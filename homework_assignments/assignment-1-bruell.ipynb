{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Problem 1: Word counts</h1>\n",
    "Write a function <span style=\"color:red\">word_count</span> that takes a text string as an argument and returns a dictionary containing the count of words in that string\n",
    "\n",
    "For example: \n",
    "\n",
    "For the  string \"It was the best of times it was the worst of times\", your function should return the following dictionary:\n",
    "\n",
    "{'It': 1,\n",
    " 'best': 1,\n",
    " 'it': 1,\n",
    " 'of': 2,\n",
    " 'the': 2,\n",
    " 'times': 2,\n",
    " 'was': 2,\n",
    " 'worst': 1}\n",
    " \n",
    " Notes:\n",
    " \n",
    " 1. Assume that there is no punctuation, not even the end of sentence period, in the string, only words separated by spaces. \n",
    " \n",
    " 2. The function <span style=\"color:red\">split</span> splits a string on spaces. An example call of the function is: <span style=\"color:red\">\"hello fellow\".split()</span> which will return the list <span style=\"color:red\">['hello', 'fellow']</span>\n",
    " \n",
    " 3. Treat words with different cases as different words (\"hello\" and \"Hello\" are not the same word)\n",
    " \n",
    " 4. You might find the <a href=\"http://book.pythontips.com/en/latest/for_-_else.html\">for ... else ...</a> structure useful for this problem \n",
    " \n",
    " 5. If the string is empty, the function should return an empty dictionary\n",
    " \n",
    " 6. Depending on your version of python, the ordering of words in your dictionary may be different from what is in my dictionary. The count matters, not the order!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(text):\n",
    "    counts = {}\n",
    "\n",
    "    #Your code goes here\n",
    "    text_list = text.split()\n",
    "    for word in text_list:\n",
    "        if word not in counts:\n",
    "            counts[word] = 1\n",
    "        else:\n",
    "            counts[word] += 1\n",
    "    \n",
    "    return counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'It': 1, 'was': 2, 'the': 2, 'best': 1, 'of': 2, 'times': 2, 'it': 1, 'worst': 1}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "#test your function with the following sample data\n",
    "\n",
    "#Should return {'It': 1, 'best': 1, 'it': 1, 'of': 2, 'the': 2, 'times': 2, 'was': 2, 'worst': 1}\n",
    "text1 = \"It was the best of times it was the worst of times\"\n",
    "print(word_count(text1))\n",
    "\n",
    "#Should return {}\n",
    "text1 = \"\"\n",
    "print(word_count(text1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Problem 2: word encodings and vocabulary</h1>\n",
    "Many text mining problems use word encodings as an input to the analytic process. The idea behind word encodings is very simple: a corpus of documents (corpus = \"many documents\" in simple English!) contains a vocabulary (the set of words used across all documents). The vocabulary is textual (\"green\", \"people\", \"carrots\") but data analysis needs  numerical data. The solution is to replace each word with a numeric code. For example, if the corpus contains two documents:\n",
    "\n",
    "doc1 = \"it was the best of times it was the worst of times\"<br>\n",
    "doc2 = \"The good times of today are the sad thoughts of tomorrow\"\n",
    "\n",
    "Then we can represent word encodings by the following dictionary (note that your numbering may be different):\n",
    "\n",
    "{'are': 9,\n",
    " 'best': 3,\n",
    " 'good': 7,\n",
    " 'it': 0,\n",
    " 'of': 4,\n",
    " 'sad': 10,\n",
    " 'the': 2,\n",
    " 'thoughts': 11,\n",
    " 'times': 5,\n",
    " 'today': 8,\n",
    " 'tomorrow': 12,\n",
    " 'was': 1,\n",
    " 'worst': 6}\n",
    " \n",
    " If you look at the dictionary carefully, the encoding process should be very clear. \"it\" was the first word in the first document and it was encoded as a 0. \"was\" was the second word and it was encoded as a 1. And so on. Each distinct word is associated with an integer and the size of the vocabulary is the number of distinct words.\n",
    " \n",
    " Write a function <span style=\"color:blue\">vocabulary</span> that takes a list of documents as an argument and returns a dictionary containing the encoded vocabulary\n",
    " \n",
    " Notes:\n",
    " \n",
    " 1. Assume that each document is a single text string containing words separated by spaces and with absolutely no punctuation (not even periods at the end)\n",
    "\n",
    "2. If the corpus is empty, the function should return an empty dictionary\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocabulary(corpus):\n",
    "    vocab = dict()\n",
    "    \n",
    "    #YOUR CODE GOES HERE\n",
    "    counter = 0 \n",
    "    for doc in corpus:\n",
    "        word_list = doc.split()\n",
    "        for word in word_list:\n",
    "            if word not in vocab:\n",
    "                vocab[word] = counter\n",
    "                counter += 1\n",
    "\n",
    "    return vocab\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'it': 0, 'was': 1, 'the': 2, 'best': 3, 'of': 4, 'times': 5, 'worst': 6, 'good': 7, 'today': 8, 'are': 9, 'sad': 10, 'thoughts': 11, 'tomorrow': 12}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "#Test your function with the following example. \n",
    "#Should return: \n",
    "{'it': 0,'was': 1,'the': 2,'best': 3,'of': 4,'times': 5,'worst': 6,'good': 7,'today': 8,'are': 9,'sad': 10,'thoughts': 11,'tomorrow': 12}#\n",
    "doc1 = \"it was the best of times it was the worst of times\"\n",
    "doc2 = \"the good times of today are the sad thoughts of tomorrow\"\n",
    "\n",
    "print(vocabulary([doc1,doc2]))\n",
    "\n",
    "doc1 = \"\"\n",
    "doc2 = \"\"\n",
    "print(vocabulary([doc1,doc2]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Problem 3: word_vectors</h1>\n",
    "The  <span style=\"color:red\">vocabulary</span> function returns a dictionary containing the word encoded vocabulary associated with the corpus. Once the encoding is done, each document can be replaced by a <span style=\"color:blue\">word vector</span> that indicates which words (from the vocabulary) are present in the document and with what frequency. For example, given the corpus:\n",
    "\n",
    "doc1 = \"it was the best of times it was the worst of times\"\n",
    "\n",
    "doc2 = \"The good times of today are the sad thoughts of tomorrow\"\n",
    "\n",
    "the word vector corresponding to doc1 is:\n",
    "\n",
    "[2, 2, 2, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "Note that the length of the vector is equal to the length of the entire vocabulary. Each location in the word vector corresponds to the code for the corresponding word in the vocabulary. The value at each location is the frequency of the word in the document. Thus, location 0 corresponds to the word \"it\" which occurs twice in the doc1. Location 3 corresponds to \"best\" which occurs once in doc1. \n",
    "\n",
    "Write a function <span style=\"color:red\">word_vectors</span> that takes a list of texts as an argument and returns a list of word vectors. \n",
    "\n",
    "Notes:\n",
    "\n",
    "1. Use the word_count function to get word frequencies\n",
    "\n",
    "2. Use the vocabulary function to get the encoded vocabulary for the corpus\n",
    "\n",
    "3. You can construct a list of zeros of a given length using <span style=\"color:blue\">[0]*n</span> where n is an integer. <span style=\"color:blue\">[0] * len(vocabulary)</span> will return a list of zeros of the length of the vocabulary. Create this list for each document and update individual locations by their corresponding frequencies in the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vectors(corpus):\n",
    "    vocab = vocabulary(corpus)\n",
    "    word_vectors = list()\n",
    "\n",
    "    #YOUR CODE GOES HERE\n",
    "    for doc in corpus:\n",
    "        doc_vector = [0] * len(vocab)\n",
    "        word_list = doc.split()\n",
    "        for word in word_list:\n",
    "            for key in vocab:\n",
    "                if key == word:\n",
    "                    doc_vector[vocab[key]] += 1\n",
    "        word_vectors.append(doc_vector)\n",
    "        \n",
    "    return word_vectors\n",
    "            \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 2, 2, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 2, 0, 2, 1, 0, 1, 1, 1, 1, 1, 1]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The function should return two lists:\n",
    "[[2, 2, 2, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0],\n",
    " [0, 0, 2, 0, 2, 1, 0, 1, 1, 1, 1, 1, 1]]\n",
    "\"\"\"\n",
    "doc1 = \"it was the best of times it was the worst of times\"\n",
    "doc2 = \"the good times of today are the sad thoughts of tomorrow\"\n",
    "word_vectors([doc1,doc2])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Problem 4: Moving averages</h1>\n",
    "Moving averages are often used in trend analysis in timeseries data. A simple way of figuring out whether a timeseries is trending (i.e., moving consistently in either the upward or downward direction) or mean reverting (i.e., fluctuating around a mean) is to see if a shorter term moving average is consistently below or above a longer term moving average. \n",
    "\n",
    "Write a function <span style=\"color:blue\">getMovingAverage(series,duration)</span> that takes a list of numbers as an input (the series) and returns a n-period (the duration) moving average series of the same length as the original list. For each k-th element in the first n-1 elements, return the average of the k elemets.\n",
    "\n",
    "For example, if:\n",
    "\n",
    "x = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "and\n",
    "\n",
    "duration = 4\n",
    "\n",
    "then, getMovingAverage(x,duration) should return:\n",
    "\n",
    "[1.0, 1.5, 2.0, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5]\n",
    "\n",
    "The average at k=0 is 1/1<br>\n",
    "The average at k=1 is (1 + 2)/2<br>\n",
    "The average at k=2 is (1 + 2 + 3)/3<br>\n",
    "The average at k=3 is (1 + 2 + 3 + 4)/4<br>\n",
    "The average at k=4 is (2 + 3 + 4 + 5)/4<br>\n",
    "etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.5, 2.0, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getMovingAverage(series,duration):\n",
    "    mvg_avg = list()\n",
    "    running_sum = 0\n",
    "\n",
    "    #YOUR CODE GOES HERE\n",
    "    numbers_in_sum = []\n",
    "    for num in series:\n",
    "        running_sum += num\n",
    "        numbers_in_sum.append(num)\n",
    "        if len(numbers_in_sum) > duration:\n",
    "            running_sum -= numbers_in_sum[0]\n",
    "            numbers_in_sum.remove(numbers_in_sum[0])\n",
    "        avg_val = running_sum / len(numbers_in_sum)\n",
    "        mvg_avg.append(avg_val)\n",
    "    \n",
    "    return mvg_avg\n",
    "    \n",
    "x = [1,2,3,4,5,6,7,8,9,10]\n",
    "getMovingAverage(x,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5]\n",
      "[1.0, 1.5, 2.0, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5]\n",
      "[]\n",
      "[1.0]\n"
     ]
    }
   ],
   "source": [
    "series = [1,2,3,4,5,6,7,8,9,10]\n",
    "print(getMovingAverage(series,2)) #[1.0, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5, 9.5]\n",
    "print(getMovingAverage(series,4)) #[1.0, 1.5, 2.0, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5]\n",
    "print(getMovingAverage([],4)) #[] (empty list)\n",
    "print(getMovingAverage([1],7)) #[1.0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "81d5b4a19a276010183013345b38f7d9b6c479ab07551a9ca40dd13abdbac5b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
