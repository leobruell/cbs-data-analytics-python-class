{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:red;font-size:60px\">Machine learning</span>\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Creating programs that learn\n",
    "<li>The \"learned\" knowledge is not explicitly contained in the program\n",
    "<li>The program is designed to learn using <b><span style=\"color:darkred\">real world data</span></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Basic ideas</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>The program contains a learning algorithm\n",
    "<li>The program is given data\n",
    "<li>The program applies the learning algorithm to the data and figures stuff out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Types of learning</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li><span style=\"color:darkblue\">Supervised learning</span>: The data set contains paired input and output features and the machine learns how to get the output from the given input. In supervised learning, both input as well as output features are used in learning. Supervised learning is used for <span style=\"color:darkgreen\">prediction</span>\n",
    "<li><span style=\"color:darkblue\">Unsupervised learning</span>: The data set contains features and the machine tries to induce concepts or knowledge from this feature set. Typically by organizing the data into \"like\" clusters. In unsupervised learning, only input features are used in learning. Unsupervised learning is used for discovering <span style=\"color:darkgreen\">hidden structures</span> in data\n",
    "<li><span style=\"color:darkblue\">Reinforcement learning</span>: Software agents that learn how to maximize a reward function in a stochastic environment. Reinforcement learning is used to learn <span style=\"color:darkgreen\">strategies</span> in interactive environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Classification</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Learn how to classify cases into one of a set of discrete categories</li>\n",
    "<li>When a new case arrives, predict which category it belongs to</li>\n",
    "<li><span style=\"color:darkblue\">binary classification</span>: classifies cases into into one of two categories</li>\n",
    "<li><span style=\"color:darkgreen\">Classification is the most common form of prediction using machine learning</span></li>\n",
    "<li>Examples:</li>\n",
    "<ol>\n",
    "    <li><span style=\"color:darkblue\">credit scoring</span>: classify loan applications into various credit risk categories (or binary loan/don't loan categories)</li>\n",
    "    <li><span style=\"color:darkblue\">stock picking</span>: classify stocks (or other financial assets) into buy/sell/hold categories</li>\n",
    "    <li><span style=\"color:darkblue\">optical character recognition</span>: classify images into letters of the alphabet</li>\n",
    "    <li><span style=\"color:darkblue\">churn</span>: identify which customers are more likely to churn (e.g., cell phone customers)</li>\n",
    "    <li><span style=\"color:darkblue\">sentence recognition</span>: classify pieces of text into well-formed or not well-formed sentences (used in natural language processing)</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Classification example</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Classifying handwritten digits into categories 0 ... 9</li>\n",
    "<li>We'll use the MNIST database - 70,000 images of digits (<span style=\"color:green\">70,000 cases</span>)</li>\n",
    "<li>each image is pixelated with 28*28 pixels (<span style=\"color:green\">784 features</span>)</li>\n",
    "<li>the class (which digit) of each image is known. We can use supervised learning</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Classification ML Models</h3>\n",
    "<li><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\">logistic regression</a></li>\n",
    "<li><a href=\"https://scikit-learn.org/stable/modules/sgd.html\">stochastic gradient descent</a></li>\n",
    "<li><a href=\"https://scikit-learn.org/stable/modules/tree.html\">Decision trees</a> and <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">random forest classifiers</a></li>\n",
    "<li><a href=\"https://scikit-learn.org/stable/modules/svm.html\">support vector machines</a></li>\n",
    "<li><a href=\"https://scikit-learn.org/stable/modules/naive_bayes.html\">naive bayes classifiers</a></li>\n",
    "<li><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\">neural network classifiers</a></li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>We will walk through one <i>binary classifier</i> to get a sense for how classification works and what we need to do to evaluate the performance of a classifier</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-size:large\">first make sure you're working with the latest version of sklearn</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__ #1.1.3 1.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<h3>Basic data preparation</h3>\n",
    "<li>Get the data from the appropriate data source</li>\n",
    "<li>Identify and organize the features and the target</li>\n",
    "<li>Separate the data into training and testing samples</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/lib/python3.9/site-packages/sklearn/datasets/_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784')\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li><span style=\"color:green\">DESCR</span>: a description of the data</li>\n",
    "<li><span style=\"color:green\">data</span>: the 70,000 * 784 features data</li>\n",
    "<li><span style=\"color:green\">target</span>: the 70,000 output feature values</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4         0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "69995     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "69996     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "69997     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "69998     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "69999     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "       pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "1          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "2          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "3          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "4          0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "...        ...  ...       ...       ...       ...       ...       ...   \n",
       "69995      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "69996      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "69997      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "69998      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "69999      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0           0.0       0.0       0.0       0.0       0.0  \n",
       "1           0.0       0.0       0.0       0.0       0.0  \n",
       "2           0.0       0.0       0.0       0.0       0.0  \n",
       "3           0.0       0.0       0.0       0.0       0.0  \n",
       "4           0.0       0.0       0.0       0.0       0.0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "69995       0.0       0.0       0.0       0.0       0.0  \n",
       "69996       0.0       0.0       0.0       0.0       0.0  \n",
       "69997       0.0       0.0       0.0       0.0       0.0  \n",
       "69998       0.0       0.0       0.0       0.0       0.0  \n",
       "69999       0.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[70000 rows x 784 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Example of pixelation</h3>\n",
    "<li>Each sample handwritten digit is divided into 784 (28x28) pixels</li>\n",
    "<li>The value in each pixel is the amount of shaded area in the pixel (max=255)</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166\n",
      "[(152, 3.0), (153, 18.0), (154, 18.0), (155, 18.0), (156, 126.0), (157, 136.0), (158, 175.0), (159, 26.0), (160, 166.0), (161, 255.0), (162, 247.0), (163, 127.0), (176, 30.0), (177, 36.0), (178, 94.0), (179, 154.0), (180, 170.0), (181, 253.0), (182, 253.0), (183, 253.0), (184, 253.0), (185, 253.0), (186, 225.0), (187, 172.0), (188, 253.0), (189, 242.0), (190, 195.0), (191, 64.0), (203, 49.0), (204, 238.0), (205, 253.0), (206, 253.0), (207, 253.0), (208, 253.0), (209, 253.0), (210, 253.0), (211, 253.0), (212, 253.0), (213, 251.0), (214, 93.0), (215, 82.0), (216, 82.0), (217, 56.0), (218, 39.0), (231, 18.0), (232, 219.0), (233, 253.0), (234, 253.0), (235, 253.0), (236, 253.0), (237, 253.0), (238, 198.0), (239, 182.0), (240, 247.0), (241, 241.0), (260, 80.0), (261, 156.0), (262, 107.0), (263, 253.0), (264, 253.0), (265, 205.0), (266, 11.0), (268, 43.0), (269, 154.0), (289, 14.0), (290, 1.0), (291, 154.0), (292, 253.0), (293, 90.0), (319, 139.0), (320, 253.0), (321, 190.0), (322, 2.0), (347, 11.0), (348, 190.0), (349, 253.0), (350, 70.0), (376, 35.0), (377, 241.0), (378, 225.0), (379, 160.0), (380, 108.0), (381, 1.0), (405, 81.0), (406, 240.0), (407, 253.0), (408, 253.0), (409, 119.0), (410, 25.0), (434, 45.0), (435, 186.0), (436, 253.0), (437, 253.0), (438, 150.0), (439, 27.0), (463, 16.0), (464, 93.0), (465, 252.0), (466, 253.0), (467, 187.0), (493, 249.0), (494, 253.0), (495, 249.0), (496, 64.0), (518, 46.0), (519, 130.0), (520, 183.0), (521, 253.0), (522, 253.0), (523, 207.0), (524, 2.0), (544, 39.0), (545, 148.0), (546, 229.0), (547, 253.0), (548, 253.0), (549, 253.0), (550, 250.0), (551, 182.0), (570, 24.0), (571, 114.0), (572, 221.0), (573, 253.0), (574, 253.0), (575, 253.0), (576, 253.0), (577, 201.0), (578, 78.0), (596, 23.0), (597, 66.0), (598, 213.0), (599, 253.0), (600, 253.0), (601, 253.0), (602, 253.0), (603, 198.0), (604, 81.0), (605, 2.0), (622, 18.0), (623, 171.0), (624, 219.0), (625, 253.0), (626, 253.0), (627, 253.0), (628, 253.0), (629, 195.0), (630, 80.0), (631, 9.0), (648, 55.0), (649, 172.0), (650, 226.0), (651, 253.0), (652, 253.0), (653, 253.0), (654, 253.0), (655, 244.0), (656, 133.0), (657, 11.0), (676, 136.0), (677, 253.0), (678, 253.0), (679, 253.0), (680, 212.0), (681, 135.0), (682, 132.0), (683, 16.0)]\n"
     ]
    }
   ],
   "source": [
    "pixels_with_values = [(val[0],val[1]) for val in enumerate(mnist['data'].loc[0]) if val[1] > 0.0]\n",
    "print(len(pixels_with_values))\n",
    "print(pixels_with_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Each handwriting sample is \"marked\", i.e., the digit it represents is known</li>\n",
    "<li>An example of the pixellation and the target is below</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        5\n",
       "1        0\n",
       "2        4\n",
       "3        1\n",
       "4        9\n",
       "        ..\n",
       "69995    2\n",
       "69996    3\n",
       "69997    4\n",
       "69998    5\n",
       "69999    6\n",
       "Name: class, Length: 70000, dtype: category\n",
       "Categories (10, object): ['0', '1', '2', '3', ..., '6', '7', '8', '9']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      "                                                        \n",
      "                                                        \n",
      "                                                        \n",
      "                                                        \n",
      "                  * * * * * * * * * *                   \n",
      "            * * * * * * * * * * * * * *                 \n",
      "            * * * * * * * *     * * * *                 \n",
      "            * * * * *           * * * *                 \n",
      "            * * *             * * * *                   \n",
      "                            * * * * *                   \n",
      "                      * * * * * * *                     \n",
      "                      * * * * * * * * *                 \n",
      "                      * * * * * * * * *                 \n",
      "                      * * *       * * * *               \n",
      "                                    * * *               \n",
      "                                      * * *             \n",
      "                                      * * *             \n",
      "                                      * *               \n",
      "                                    * * *               \n",
      "                                  * * * *               \n",
      "                  * * *         * * * * *               \n",
      "                * * * * * * * * * * * *                 \n",
      "                * * * * * * * * * * *                   \n",
      "                  * * * * * * * *                       \n",
      "                                                        \n",
      "                                                        \n",
      "                                                        \n",
      "Actual value:  3\n"
     ]
    }
   ],
   "source": [
    "def display_digit(digit_number):\n",
    "    for line in mnist.data.to_numpy()[digit_number].reshape(28,28):\n",
    "        for num in line:\n",
    "            if num > 0:\n",
    "                print('*', end = ' ')\n",
    "            else:\n",
    "                print(' ', end = ' ')\n",
    "        print('')\n",
    "    print(\"Actual value: \",mnist.target.to_numpy()[digit_number])\n",
    "display_digit(32775)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:blue;font-size:large\">train, test, and holdout</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li><span style=\"color:green\">training dataset</span>: the dataset that the machine uses to learn whatever it is that it is supposed to learn</li>\n",
    "<ul><li>Because we're training a model on the data, the model is likely to be \"biased\" toward the training data</li>\n",
    "    <li>Consequently, as second dataset, unseen during the training, is used to provide an \"unbiased\" evaluation of the model performance</li>\n",
    "</ul>\n",
    "<li><span style=\"color:green\">validation/testing dataset</span>: the dataset that is used to test how well the machine has learned from the training set (the machine does not learn from this dataset and, therefore, it provides an unbiased evaluation of the model)</li>\n",
    "<li><span style=\"color:green\">holdout dataset</span>: the ML process is iterative. After multiple training and testing cycles, the data scientist settles on a model. A third dataset is sometimes used to test this final model</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:blue;font-size:large\">prepare a train and test dataset</h3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Assemble the X and y in a dataframe</h3>\n",
    "<li>The sample and the target will be aligned in the same row</li>\n",
    "<li>splitting the data into train and test will be easier</li>\n",
    "<li>let X be the independent variable dataframe and y the target series</li>\n",
    "<li>first add target (y) as a new column of X</li>\n",
    "<li>then use sklearn's train_test_split function to split the set into two</li>\n",
    "<li>we'll also reduce the datasize to 30% so that the analysis can work in the class!</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "X,y = mnist['data'],mnist['target']\n",
    "#the pd.assign function adds one or more pandas series as a new column(s) to a dataframe\n",
    "#The function returns a copy\n",
    "df = X.assign(target = y)\n",
    "\n",
    "#Randomly sample 30% of the data without replacement (to speed up in class analysis)\n",
    "df = df.sample(frac=.3,random_state=42)\n",
    "\n",
    "#Split the data into two dataframes randomly assigning rows to one of two sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size = 0.3,random_state=3456)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46730</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48393</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41416</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34506</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43725</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19036</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51256</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48198</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "46730     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "48393     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "41416     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "34506     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "43725     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "1216      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "19036     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "51256     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "48198     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2571      0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "       pixel10  ...  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "46730      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "48393      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "41416      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "34506      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "43725      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "...        ...  ...       ...       ...       ...       ...       ...   \n",
       "1216       0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "19036      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "51256      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "48198      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "2571       0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "       pixel781  pixel782  pixel783  pixel784  target  \n",
       "46730       0.0       0.0       0.0       0.0       8  \n",
       "48393       0.0       0.0       0.0       0.0       4  \n",
       "41416       0.0       0.0       0.0       0.0       8  \n",
       "34506       0.0       0.0       0.0       0.0       7  \n",
       "43725       0.0       0.0       0.0       0.0       7  \n",
       "...         ...       ...       ...       ...     ...  \n",
       "1216        0.0       0.0       0.0       0.0       7  \n",
       "19036       0.0       0.0       0.0       0.0       1  \n",
       "51256       0.0       0.0       0.0       0.0       2  \n",
       "48198       0.0       0.0       0.0       0.0       4  \n",
       "2571        0.0       0.0       0.0       0.0       5  \n",
       "\n",
       "[21000 rows x 785 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Basic ML Terminology</span>\n",
    "<li><span style=\"color:darkblue\">Feature</span>: A (measurable) property of the learning domain\n",
    "<li><span style=\"color:darkblue\">Feature set</span>: The set of features that are useful for learning in a given domain and a given problem\n",
    "<ul>\n",
    "<li>gender, age, income, other demographic data for predicting credit risk\n",
    "<li>position of pupil, size of nose, presence/absence of dimples in facial data for facial recognition\n",
    "<li>color, intensity of pixels in image data for image recognition\n",
    "<li>moving averages, departures, technical indicators, price in stock price prediction\n",
    "</ul>\n",
    "<li><span style=\"color:darkblue\">Input features/Independent variables</span>: The observable (useful) features in the domain\n",
    "<li><span style=\"color:darkblue\">Output features/Dependent variable</span>: A feature that is being learned or predicted\n",
    "<ul>\n",
    "<li>In stock price prediction: moving averages, departures, technical indicators may be input features and the future return the output feature\n",
    "<li>In face recognition: various observable facial features are the input feature and the person (name?) the output feature\n",
    "</ul>\n",
    "<li><span style=\"color:green\">variance</span>: an estimate of how much the model metrics (e.g., the mean square error) will change with different data sets. In a good model, the metric values should be the same in the training sample, the testing sample, as well as in all future unseen samples</li>\n",
    "\n",
    "<li><span style=\"color:green\">overfitting</span>: variance in a dataset comes from two sources: <span style=\"color:blue\">informed features</span> and <span style=\"color:blue\">noise</span>. Informed features are those features that actually explain the target feature. Noise refers to features that happened to co-occur with the target but were not explanatory. But, the machine learns and tests its learning by looking at available data which contains both informed features as well as noise and the danger is that the machine will learn the noise better than the data. When that happens, the model is said to be overfitted and it will not perform well out of sample</li>\n",
    "<li><span style=\"color:green\">bias</span>: a model that does not capture enough variance (i.e., it misses informed features) is said to be biased. A biased model will not learn well enough to perform out of sample\n",
    "    <ul>\n",
    "        <li>For example, a stock prediction model that only uses data from a low interest rate regime will ignore interest rate as an informed feature. The model may not perform well if interest rates rise</li>\n",
    "    </ul>\n",
    "\n",
    "<li><span style=\"color:green\">bias-variance tradeoff</span>: we can collect data on many features. The more features that get incorporated into a model, the more likely we are to capture informed features (reducing bias). However, we are also more likely to capture features that are merely noise (increasing the possibility of overfitting). The bias-variance tradeoff is one of the biggest problems in machine learning\n",
    "\n",
    "<li><span style=\"color:green\">model complexity</span>: model complexity is a factor of the number of features that a model includes (more features = more complex) and the nature of the model itself (a linear model is less complex than a non-linear one)\n",
    "    \n",
    "<li><span style=\"color:green\">linear models</span>: models that learn a linear relationship between the input features \n",
    "\n",
    "<li><span style=\"color:green\">regularization</span>: a technique used to penalize complexity in a model. Model complexity leads to overfitting and regularization is used to decrease the probability of that happening. \n",
    "\n",
    "\n",
    "<li><span style=\"color:green\">regression</span>: a linear model that estimates the coefficients of a line $$ y = { \\alpha + \\beta_1}x_1 + {\\beta_2}x_2 + ..... + {\\beta_n}x_n + {\\epsilon} $$ by minimizing the <span style=\"color:blue\">sum of square differences</span> between the actual and estimated target values</li>\n",
    "\n",
    "<li><span style=\"color:green\">regularized regression</span>: regression which explicitly penalizes high betas in the estimated line to reduce the complexity of the model</li>\n",
    "\n",
    "<li><span style=\"color:green\">logistic regression</span>: regression that classifies data into two categories (binary - 0/1 - classification) using a \"logit model\". Roughly (definitely not exactly!), in logistic regression, the model assumes a linear relationship between input features and the probability that the output value is 1. A threshold value then determines whether the estimate is a 0 or a 1. </li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"bias_variance.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Our problem</h2>\n",
    "<li>We'll build a simple binary classifier using this handwritten digits data</li>\n",
    "<li><b>Our question</b>: How well does our classifier do in identifying whether a particular digit is an 8 or is not an 8</li>\n",
    "<li>We'll use the stochastic gradient descent classifier</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Stochastic gradient descent classifier</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>gradient descent is used to move incrementally toward the solution, always moving in the direction of the optimal solution</li>\n",
    "<li>rough example of SGD and linear regression:</li>\n",
    "<ol>\n",
    "    <li>parameterize the linear function with a set of beta values</li>\n",
    "    <li>estimate the cost (actual - target) for one, randomly sampled, example</li>\n",
    "    <li>update the model parameters using an <b>update rule</b> (see the <a href=\"https://scikit-learn.org/stable/modules/sgd.html#mathematical-formulation\">mathematical formulation of SGD</a> for details)</li>\n",
    "    <li>Repeat for other examples until a stopping rule (number of iterations/prediction error/change in prediction error/etc.) is activated</li>\n",
    "<li>easy to generalize this procedure for any cost function (that is differentiable)</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:blue;font-size:large\">Training the SGD classifier</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>set up the train and test data\n",
    "<li>first, create a binary True/False column as the new target feature</li>\n",
    "<li>import the SGDClassifier model from sklearn</li>\n",
    "<li><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html</a></li>\n",
    "<li><a href=\"https://scikit-learn.org/stable/modules/sgd.html#sgd\">stochastic gradient descent user guide</a></li>\n",
    "<li>shuffle the data</li> \n",
    "<li>parameterize the model</li>\n",
    "<li><span style=\"color:green\">fit</span> the model</li>\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:blue;font-size:large\">Binary classification with Stochastic Gradient Descent</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Let's see if we can classify digits as 8 or not 8</li>\n",
    "<li>first, we need to transform the y value from 0, 1, ,2, ... to True or 1 (is a 8) or False or 0 (is not a 8)</li>\n",
    "<li>use a boolean mask as the target</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a binary column\n",
    "train['y'] = (train['target'] == '8')\n",
    "test['y'] = (test['target'] == '8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle training data and extract X and y (sample defaults to without replacement)\n",
    "#shuffling is useful in case there is serial correlation in the data \n",
    "\n",
    "train = train.sample(frac=1.0,random_state=42) \n",
    "X_train = train.iloc[:,0:784]\n",
    "y_train = train['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the test set\n",
    "X_test = test.iloc[:,0:784]\n",
    "y_test = test['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:blue;font-size:large\">Fit the data to the model</span>\n",
    "<li>Fitting, in ML, is the process of estimating the parameters of the model</li>\n",
    "<li>In linear regression, the parameters are alpha and the betas</li>\n",
    "<li>Regardless of the actual ML model being used, the process is the same</li>\n",
    "<ul>\n",
    "    <li>Create a model object with hyperparameter values</li>\n",
    "    <li>Fit the training data</li>\n",
    "    <li>Evaluate the model</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(alpha=5.0, loss=&#x27;log_loss&#x27;, max_iter=200, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(alpha=5.0, loss=&#x27;log_loss&#x27;, max_iter=200, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDClassifier(alpha=5.0, loss='log_loss', max_iter=200, random_state=42)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "#Create a model object. Parameters of the model object are known as hyper parameters\n",
    "clf = SGDClassifier(random_state=42,max_iter=200,loss=\"log_loss\",alpha=5.0) \n",
    "\n",
    "#Fit the data to the model. This estimates the model parameters \n",
    "#Model parameters and hyper parameters are different (more on this later)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Evaluating a binary classifier</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>eyeball predictions</li>\n",
    "<li>cross-validation</li>\n",
    "<li>accuracy</li>\n",
    "<li>confusion matrices</li>\n",
    "<li>precision/recall</li>\n",
    "<li>ROC curve</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>the <span style=\"color:green\">predict</span> function returns predicted y values given a set of X values</li>\n",
    "<li>Let's check a couple of data points to see if the predictions are correct</li> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46183    False\n",
       "12639    False\n",
       "51323    False\n",
       "748      False\n",
       "38497    False\n",
       "14278    False\n",
       "52842    False\n",
       "46655    False\n",
       "19735    False\n",
       "39022    False\n",
       "45473    False\n",
       "67843    False\n",
       "43190    False\n",
       "49053    False\n",
       "2351     False\n",
       "21978    False\n",
       "17119    False\n",
       "48188    False\n",
       "12462    False\n",
       "19223     True\n",
       "Name: y, dtype: bool"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.iloc[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:blue;font-size:large\">hmm. so far so good!</span>\n",
    "<li>but, eyeballing a couple of cases is not a good evaluation mechanism</li>\n",
    "<li>or, the plural of anecdote is not data!</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Formal metrics for evaluating a binary classifier</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<h2 style=\"color:blue;\">Classification Model evaluation: Confusion matrix</h2>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>A confusion matrix evaluates each data point in the testing dataset to see which of the following categories it falls into: \n",
    "<ol>\n",
    "<li><span style=\"color:blue\">true positive</span>: model predicts a 8 and it is an 8\n",
    "<li><span style=\"color:blue\">false positive</span>: model predicts a 8 but it is a not 8\n",
    "<li><span style=\"color:blue\">true negative</span>: model predicts a not 8 and it is a not 8\n",
    "<li><span style=\"color:blue\">false negative</span>: model predicts a not 8 and it is actually an eight\n",
    "</ol>\n",
    "<li>It then reports the number (or proportion) of cases in each category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>the structure of the confusion matrix is:</li>\n",
    "<table>\n",
    "    <tr><td></td><th>predicted negatives</th><th>predicted positives</th></tr>\n",
    "    <tr><th>actual negatives</th><td>true negative</td><td>false positive</td></tr>\n",
    "    <tr><th>actual positives</th><td>false negative</td><td>true positive</td></tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13038,   277],\n",
       "       [  379,  1006]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_train_pred = clf.predict(X_train)\n",
    "cfm = confusion_matrix(y_train,y_train_pred)\n",
    "cfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5554,  139],\n",
       "       [ 205,  402]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_test_pred = clf.predict(X_test)\n",
    "cfm = confusion_matrix(y_test,y_test_pred)\n",
    "cfm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:blue;font-size:large\">Confusion matrix metrics</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the results of the confusion matrix, we can calculate a number of metrics that will help evaluate the model\n",
    "<ol>\n",
    "<li><span style=\"color:blue\">true positive rate</span> or <span style=\"color:blue\">sensitivity</span> or <span style=\"color:blue\">recall</span>\n",
    "<li><span style=\"color:blue\">true negative rate</span> or <span style=\"color:blue\">specificity</span>\n",
    "<li><span style=\"color:blue\">false positive rate</span> or <span style=\"color:blue\">fall out</span>\n",
    "<li><span style=\"color:blue\">precision</span> or <span style=\"color:blue\">positive predictive value</span>\n",
    "<li><span style=\"color:blue\">f-score</span>\n",
    "<li><span style=\"color:blue\">accuracy</span>\n",
    "<li><span style=\"color:blue\">misclassification rate</span>\n",
    "\n",
    "\n",
    "</ol>\n",
    "<li>Note that our positive values are \"is a 8\" and negative values are \"is not a 8\"</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not 8 correctly classified as not 8 (tn)          \t5554\n",
      "Not 8 incorrectly classified as a 8 (fp)          \t139\n",
      "8 incorrectly classified as not 8 (fn)            \t205\n",
      "8 correctly classified as a 8 (tp)                \t402\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = cfm.ravel() #ravel flattens an array\n",
    "print(\"%-50s\\t%d\"%(\"Not 8 correctly classified as not 8 (tn)\",tn))\n",
    "print(\"%-50s\\t%d\"%(\"Not 8 incorrectly classified as a 8 (fp)\",fp))\n",
    "print(\"%-50s\\t%d\"%(\"8 incorrectly classified as not 8 (fn)\",fn))\n",
    "print(\"%-50s\\t%d\"%(\"8 correctly classified as a 8 (tp)\",tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax=np.array([[1,2,3],[4,5,6]])\n",
    "np.ravel(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:blue;font-size:large\">True Positive rate/sensitivity/recall</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True Positive Rate is the proportion of positive cases that are correctly identified as positive\n",
    "$$ tpr = \\frac{tp}{(tp + fn)} $$\n",
    "Sensitivity is a measure of how good our model is in identifying the positive condition. A value of 1, for example, will mean that every positive value (every eight) was correctly idenfified by the model. \n",
    "<li>Percentage of persons with COVID correctly identified as having COVID\n",
    "<li>Percentage of \"fake news\" items correctly identified as fake news\n",
    "<li>Percentage of consumers who click on an ad and the model correctly predicts they will click on the ad\n",
    "<li>Percentage of customers who churn (move to a new carrier) and the model correctly predicts they will churn\n",
    "<li><b>Note that the true positive rate can be made high by just guessing that every case is positive</b></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of eights correctly identified as eights: 0.6622734761120264\n"
     ]
    }
   ],
   "source": [
    "tpr = tp/(tp+fn) #note that the denominator is the number of 8s\n",
    "print(\"Percentage of eights correctly identified as eights:\",tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:blue;font-size:large\">True Negative Rate or Specificity</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True Negative Rate is the proportion of negative cases that are correctly identified as negative\n",
    "$$ tpr = \\frac{tn}{(tn + fp)} $$\n",
    "<li>Proportion of cases that are COVID free that are correctly identified as COVID free</li>\n",
    "<li>Proportion of real news stories that are correctly identified as real news\n",
    "<li>Proportion of healthy people that are correctly identified as healthy\n",
    "<li><b>Note that this will be 1 if everything is guessed as a non-8</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of estimated non-8s correctly identified 0.975584050588442\n"
     ]
    }
   ],
   "source": [
    "tnr = tn/(tn+fp) #note that the denominator is the number of non-8s\n",
    "print(\"percentage of estimated non-8s correctly identified\",tnr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:blue;font-size:large\">false positive rate or \"fall out\"</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The false positive rate is the proportion of negative cases that have been identified as positives\n",
    "$$ fpr = \\frac{fp}{(fp + tn)} $$\n",
    "\n",
    "<li>Proportion of people who don't have COVID but the model says they do</li>\n",
    "<li>Proportion of true news items that are identified as fake news\n",
    "<li>Proportion of consumers who won't use a discount but are identified as target discount users\n",
    "<li>equals 1-tnr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the proportion of non 8s misclassified as an 8 0.024415949411558054\n"
     ]
    }
   ],
   "source": [
    "fpr = fp/(fp+tn) #note that the denominator is the number of non 8s\n",
    "print(\"the proportion of non 8s misclassified as an 8\",fpr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:blue;font-size:large\">Precision</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision measures the proportion of cases identified as positive that are actually positive\n",
    "$$ precision = \\frac{tp}{(tp + fp)} $$\n",
    "<li>Proportion of people that the model says have COVID and they actually have COVID</li>\n",
    "<li>Proportion of news items that are actually fake from amongst all the news items that are identified as fake\n",
    "<li>Proportion of \"churners\" that are actual churners from amongst all customers identifed as churners\n",
    "<li>Proportion of actual 8s amongst all things that are identified as 8s\n",
    "<li><b>Note that if we predict exactly one case as positive, and that case is actually positive, precision will be 100%</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proportion of cases identified as 8s that are actually 8s 0.7430683918669131\n"
     ]
    }
   ],
   "source": [
    "precision = tp/(tp+fp) #note that the denominator is all things classified as a 8\n",
    "print(\"proportion of cases identified as 8s that are actually 8s\",precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:blue;font-size:large\">f-score</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Precision tells us how well our model discriminates amongst cases it identifies as positive. A precision of 1 would mean that if our model says something is positive, it is definitely a positive. \n",
    "<li>Recall (true positive rate) tells us how good the model is at finding positives (a recall of 1 would mean it has found all positives). <li>Precision does not tell us how good we are at finding positives while recall does not tell us how good our model is at disciminating\n",
    "<li>We can increase recall by increasing the number of positive predictions, but this will hurt precision</li>\n",
    "<li>We can increase precision by decreasing the number of positive predictions and (hopefully) being more correct, but this will hurt recall</li>\n",
    "<li>The f-score combines the two into a single score using the harmonic mean of the two numbers to help trade-off the two scores:\n",
    "    \n",
    "$$ F = 2\\frac{precision * recall}{(precision + recall)} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7003484320557491\n"
     ]
    }
   ],
   "source": [
    "f = precision*tpr/(precision+tpr)*2\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:blue;font-size:large\">accuracy</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy measures how accurately the model classifies things as positive or negative (8s or non 8s)\n",
    "$$accuracy = \\frac{tp + tn}{(tp+tn+fp+fn)} $$\n",
    "An accuracy of 1 would mean that our model has classified everything correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy 0.9453968253968253\n"
     ]
    }
   ],
   "source": [
    "accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "print(\"classification accuracy\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:blue;font-size:large\">misclassification rate</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misclassifican rate is the inverse of accuracy. What proportion of the cases are misclassified?\n",
    "$$ misclassificationRate = \\frac{fp + fn}{(tp+tn+fp+fn)} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proportion misclassified 0.054603174603174605\n"
     ]
    }
   ],
   "source": [
    "misclassification_rate = (fp + fn)/(tp+fp+tn+fn)\n",
    "print(\"proportion misclassified\",misclassification_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:blue;font-size:large\">Summarizing our results</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY: correctly assigning a category 0.9453968253968253\n",
      "RECALL/TPR: proportion of 8s correctly identified: 0.6622734761120264\n",
      "PRECISION: proportion of things identified as 8 that are 8 0.7430683918669131\n",
      "SPECIFICITY/TNR: percentage of non-8s correctly identified 0.975584050588442\n",
      "F1 SCORE:  0.7003484320557491\n"
     ]
    }
   ],
   "source": [
    "accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "print(\"ACCURACY: correctly assigning a category\",accuracy)\n",
    "tpr = tp/(tp+fn) #note that the denominator is the number of 8s\n",
    "print(\"RECALL/TPR: proportion of 8s correctly identified:\",tpr)\n",
    "precision = tp/(tp+fp) #note that the denominator is all things classified as an 8\n",
    "print(\"PRECISION: proportion of things identified as 8 that are 8\",precision)\n",
    "tnr = tn/(tn+fp) #note that the denominator is the number of non-8s\n",
    "print(\"SPECIFICITY/TNR: percentage of non-8s correctly identified\",tnr)\n",
    "f = f = precision*tpr/(precision+tpr)*2\n",
    "print(\"F1 SCORE: \",f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">Model Selection Strategies</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Some binary classification models like the SGD (with log loss) can compute predictions as probabilities </li>\n",
    "<li>A <span style=\"color:blue\">loss function</span> in regression models is used to calculate the prediction error</li>\n",
    "<li>Sklearn then picks the 0.5 as a threshhold</li>\n",
    "<li>Values above 0.5 are predicted as positive while values below 0.5 are predicted as negative</li>\n",
    "<li>By varying the threshhold, it is possible to vary the precision, recall, accuracy etc.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluate the model</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>On training data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(alpha=5.0, loss=&#x27;log_loss&#x27;, max_iter=200, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(alpha=5.0, loss=&#x27;log_loss&#x27;, max_iter=200, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDClassifier(alpha=5.0, loss='log_loss', max_iter=200, random_state=42)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9553741496598639, 0.7263537906137184, 0.784099766173032)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score,recall_score,accuracy_score\n",
    "y_train_pred = clf.predict(X_train)\n",
    "accuracy = accuracy_score(y_train,y_train_pred)\n",
    "recall = recall_score(y_train,y_train_pred)\n",
    "precision = precision_score(y_train,y_train_pred)\n",
    "accuracy, recall, precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>On testing data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9453968253968253, 0.6622734761120264, 0.7430683918669131)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test,y_test_pred)\n",
    "recall = recall_score(y_test,y_test_pred)\n",
    "precision = precision_score(y_test,y_test_pred)\n",
    "accuracy, recall, precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Getting the probabilities</h4>\n",
    "<li><span style=\"color:green\">predict_proba</span> works like predict but returns the probability of each class for each case </li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.04812033e-04, 4.58029591e-03, 6.33005650e-04, ...,\n",
       "       9.64064907e-02, 6.13957514e-01, 2.48335142e-03])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_probabilities = clf.predict_proba(X_train)\n",
    "prob_array = prediction_probabilities[:,1]\n",
    "prob_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9998077399948154, 1.6662230363607759e-12, 0.11149675030419366)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_array.max(),prob_array.min(),prob_array.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Now, we can see how the metrics change with changes in the threshold</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n",
      "precision:  0.3012699905926623\n",
      "recall:  0.9249097472924188\n",
      "accuracy:  0.7908163265306123\n",
      "\n",
      "\n",
      "\n",
      "0.4\n",
      "precision:  0.7187079407806191\n",
      "recall:  0.7711191335740072\n",
      "accuracy:  0.95\n",
      "\n",
      "\n",
      "\n",
      "0.5\n",
      "precision:  0.784099766173032\n",
      "recall:  0.7263537906137184\n",
      "accuracy:  0.9553741496598639\n",
      "\n",
      "\n",
      "\n",
      "0.6\n",
      "precision:  0.8322869955156951\n",
      "recall:  0.6700361010830325\n",
      "accuracy:  0.9561904761904761\n",
      "\n",
      "\n",
      "\n",
      "0.8\n",
      "precision:  0.910941475826972\n",
      "recall:  0.5169675090252708\n",
      "accuracy:  0.9497278911564626\n",
      "\n",
      "\n",
      "\n",
      "0.9\n",
      "precision:  0.9397810218978102\n",
      "recall:  0.37184115523465705\n",
      "accuracy:  0.9385714285714286\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for threshold in (0.05, 0.4, 0.5, 0.6, 0.8, 0.9):\n",
    "    print(threshold)\n",
    "    y_pred_revised = prob_array > threshold\n",
    "    print(\"precision: \", precision_score(y_train, y_pred_revised)) #originally 75%\n",
    "    print(\"recall: \",recall_score(y_train, y_pred_revised)) #originally 88%\n",
    "    print(\"accuracy: \", accuracy_score(y_train, y_pred_revised)) #originally 97%\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "precision:  0.38130563798219586\n",
      "recall:  0.8467874794069192\n",
      "accuracy:  0.8528571428571429\n",
      "\n",
      "\n",
      "\n",
      "0.2\n",
      "precision:  0.5229455709711847\n",
      "recall:  0.8072487644151565\n",
      "accuracy:  0.9104761904761904\n",
      "\n",
      "\n",
      "\n",
      "0.4\n",
      "precision:  0.6875\n",
      "recall:  0.7067545304777595\n",
      "accuracy:  0.9407936507936508\n",
      "\n",
      "\n",
      "\n",
      "0.5\n",
      "precision:  0.7430683918669131\n",
      "recall:  0.6622734761120264\n",
      "accuracy:  0.9453968253968253\n",
      "\n",
      "\n",
      "\n",
      "0.6\n",
      "precision:  0.8013100436681223\n",
      "recall:  0.6046128500823723\n",
      "accuracy:  0.9474603174603174\n",
      "\n",
      "\n",
      "\n",
      "0.8\n",
      "precision:  0.9057239057239057\n",
      "recall:  0.443163097199341\n",
      "accuracy:  0.9419047619047619\n",
      "\n",
      "\n",
      "\n",
      "0.9\n",
      "precision:  0.9406392694063926\n",
      "recall:  0.3393739703459638\n",
      "accuracy:  0.9342857142857143\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction_probabilities_test = clf.predict_proba(X_test)\n",
    "prob_array_test = prediction_probabilities_test[:,1]\n",
    "prob_array_test\n",
    "for threshold in (0.1,0.2, 0.4, 0.5, 0.6, 0.8, 0.9):\n",
    "    print(threshold)\n",
    "    y_pred_revised = prob_array_test > threshold\n",
    "    print(\"precision: \", precision_score(y_test, y_pred_revised)) #originally 75%\n",
    "    print(\"recall: \",recall_score(y_test, y_pred_revised)) #originally 88%\n",
    "    print(\"accuracy: \", accuracy_score(y_test, y_pred_revised)) #originally 97%\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:red;font-size:x-large\">precision-recall tradeoff</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>we can increase precision by focusing on correctly identifying 8s while identifying fewer 8s overall</li>\n",
    "<li>but this will decrease recall because we'll be missing a lot of actual 8s</li>\n",
    "<li>generally, precision and recall trade each other off</li>\n",
    "<li>sometimes, we want higher precision (e.g., if we're identifying spam emails but are unwilling to mark a non-spam email as spam)</li>\n",
    "<li>sometimes, we want higher recall (e.g., if we want to find the effective set of customers for a discount but don't care if a few not so good customers end up in that set)</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>sklearn also constructs a precision_recall_curve giving the precision and recall at each threshold value</li>\n",
    "<li>we can use this, along with the scores to actively tradeoff precision and recall</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay at 0x7f9a580f3c40>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "PrecisionRecallDisplay.from_estimator(clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Average Precision (AP)</b> is the weighted mean of precisions at each threshold; the weight is the increase in recall from the prior threshold\n",
    "\n",
    "<li>The interpretation of average precision is that a high AP value indicates that the model is doing a good job of identifying positives while minimizing false positives. Roughly speaking, as the threshold goes down, the recall increases by x% and the precision decreases by y%. A high average precision indicates that y% is consistently less than x% (the gain in recall does not come with a higher loss in precision)</li>\n",
    "<li>The average precision metric can be used to compare models and can be used to set a threshold that trades off precision with recall (depending on what makes sense in the problem domain)</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>In our model, we don't have much room for improvement since the precision remains high and drops off only close to very low threshold values</li>\n",
    "<li>But, if precision is more important than recall, we can go for a very high threshold value with gains in precision without much loss in recall</li>\n",
    "<li>this is supported, not only by the calculations, but also by the high AP score</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:green;font-size:xx-large\">ROC: Receiver Operating Characteristic (ROC)</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red;font-size:x-large\">\n",
    "Trading off true positive rate and false positive rate</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>the true positive rate (recall or the proportion of actual 8s we identify as 8s) and false positive rate (what proportion of non-8s we have identified as 8s) compete</li>\n",
    "<li>we can increase the true positive rate by using a model that says every case is a positive</li>\n",
    "<li>but that will increase the false positive rate as well</li>\n",
    "<li>trade-off between the two is done using ROC (Receiver Operating Characteristic) curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>ROC is a way of measuring the efficacy (goodness) or a model</li>\n",
    "<li>ROC is primarily used to compare models (and compare a model against a random classifier)</li>\n",
    "<li>The ROC curve pairs the (TPR, FPR) at each threshold point and plots a line with the FPR on the x-axis and the TPR on the y-axis</li>\n",
    "<li>The <span style=\"color:blue\">area under the curve (auc)</span> of this line gives us a measure of the efficacy of the model</li>\n",
    "<ul>\n",
    "    <li>AUC of 0.5 tells us that our machine is no better than a random positive/negative picker</li>\n",
    "    <li>AUC of 1.0 tells us that our machine is the perfect classifier</li>\n",
    "</ul>\n",
    "<li>At the lower threshold values, both fpr and tpr will be high </li>\n",
    "<ul>\n",
    "    <li>since almost all cases will be predicted as positive the tpr will be high</li>\n",
    "    <li>since almost all non-positive cases will be predicted as positive the fpr will be high</li>\n",
    "</ul>\n",
    "<li>At the higher threshold values, both fpr and tpr will be low</li>\n",
    "<ul>\n",
    "    <li>since almost all cases will be predicted as negative the fpr will be low</li>\n",
    "    <li>since almost all positive cases will be predicted as negative the tpr will be low</li>\n",
    "</ul>\n",
    "<p></p>\n",
    "<img src=\"roc.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Best model ROC curve</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x7f9a47ba5b50>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "RocCurveDisplay.from_estimator(clf,X_test, y_test)\n",
    "\n",
    "#RocCurveDisplay.from_predictions(y_train,prob_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red;font-size:x-large\">reading the ROC curve</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Take the point on the curve where the TPR is 0.9</li>\n",
    "<li>At the threshold at this point, we've identified 90% of the true positives</li>\n",
    "<li>and have a FPR of arould .2</li>\n",
    "<li>fpr = 1-tnr, so the tnr = 0.80, or we've correctly identified 80% of non 8's as non 8</li>\n",
    "<li>as the tpr goes up, the tnr goes down (which leads us to the case where tpr=100% and tnr=0%)</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Understanding AUC</h3>\n",
    "<li>AUC tells us how well our model separates positive and negative cases</li>\n",
    "<li>Consider the following probabilities assigned to each case by a classification model (sorted by prob) and the corresponding actual y values</li>\n",
    "<pre>\n",
    "(0.15, 0.19, 0.26, 0.41, 0.44, 0.57, 0.65, 0.73, 0.88, 0.91)\n",
    "(F, F, F, T, T, T, T, T, T, T)\n",
    "\n",
    "\n",
    "</pre>\n",
    "Since the model can pick a threshold (e.g., 0.3) that will clearly separate the negatives from the positives, the model predictions will be:\n",
    "<pre>\n",
    "(0.15, 0.19, 0.26, 0.41, 0.44, 0.57, 0.65, 0.73, 0.88, 0.91)\n",
    "(F, F, F, T, T, T, T, T, T, T)\n",
    "\n",
    "\n",
    "</pre>\n",
    "\n",
    "with an accuracy of 100%, the AUC of this model is 1.0. Our model can cleanly separate the positive an negative cases\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now consider this slightly tweaked version\n",
    "<pre>\n",
    "(0.15, 0.19, 0.26, 0.41, 0.44, 0.57, 0.65, 0.73, 0.88, 0.91)\n",
    "(F, T, F, F, T, T, T, T, T, T)\n",
    "\n",
    "</pre>\n",
    "In this model, there is no threshold that will cleanly separate the positive and negative cases If, for example, we choose a threshold of 0.42, the model predicts:\n",
    "<pre>\n",
    "(F, F, F, F, T, T, T, T, T, T)\n",
    "</pre>\n",
    "with an accuracy of 90% (it gets 9 right and 1 wrong)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Calculating the AUC</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9047619047619048"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "target = (0, 1, 0, 0, 1, 1, 1, 1, 1, 1)\n",
    "probs = (0.15, 0.19, 0.26, 0.41, 0.44, 0.57, 0.65, 0.73, 0.88, 0.91)\n",
    "paired = list(zip(target,probs))\n",
    "\n",
    "#Separate the data into two sets\n",
    "#set1 contains the data with actual value 1 and the model determined probability\n",
    "#set2 contains the data with actual value 0 and the model determined probability\n",
    "set1 = [p for p in paired if p[0]==1]\n",
    "set0 = [p for p in paired if p[0]==0]\n",
    "\n",
    "#Compute the cross product of all pairs (7 1's * 3 0's gives 21 pairs)\n",
    "all_pairs = list(itertools.product(set1, set0))\n",
    "\n",
    "#Create three sets (only 2 are necessary)\n",
    "#A pair is concordant if the probability of the 1 is greater than the prob of the 0\n",
    "#A pair is discordant if the probability of the 0 is greater than the prob of the 1\n",
    "#A pair is tied if the probabilities are equal\n",
    "concordant_pairs = [p for p in all_pairs if p[0][1]>p[1][1]]\n",
    "discordant_pairs = [p for p in all_pairs if p[1][1]>p[0][1]]\n",
    "tied_pairs = [p for p in all_pairs if p[0][1]==p[1][1]]\n",
    "\n",
    "#Get the percent of concordant, discordant and tied\n",
    "percent_concordant = 100*len(concordant_pairs)/len(all_pairs)\n",
    "percent_discordant = 100*len(discordant_pairs)/len(all_pairs)\n",
    "percent_tied = 100*len(tied_pairs)/len(all_pairs)\n",
    "\n",
    "#Calculate the AUC\n",
    "auc = (percent_concordant + 0.5*percent_tied)/100\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Question</h3>\n",
    "<li>Why is the AUC 0.5 with a random model?</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red;font-size:x-large\">What ROC curves bring to the table</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>the AUC gives a quick estimate of the skill of the model in prediction because it tells us how good the model is at separating 1s and 0s</li>\n",
    "<li>ROC curves from different models can be visually compared to see which models are better (more skillful)</li>\n",
    "<li>Note that at a threshold of 0.5, a less skilled number may have a higher metric (e.g., accuracy) value. But the model skill is more important because a more skilled model is more likely to do better on unseen data</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red;font-size:x-large\">ROC curves vs. Precision/Recall curves</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>prefer ROC curves when the two binary value cases are relatively balanced in the dataset</li>\n",
    "<ul>\n",
    "    <li>If the data is unbalanced, the AUC will be high cases are skewed toward one side or the other (think of the cross product above)</li>\n",
    "    <li>But, you should use the AUC to <b>compare</b> models</li>\n",
    "    <li>Also note that model accuracy may be unhelpful</li>\n",
    "    </ul>\n",
    "\n",
    "<li>if the cases are unbalanced, prefer the model with the right mix of high precision and high recall</li>\n",
    "<li>Note that both precision as well as recall are positive case focused (no negatives in the calculation)</li>\n",
    "<li>Skewed models tend to have many negatives and few positives</li>\n",
    "<ul>\n",
    "    <li>precision will give an estimate of the probability that what the model says is positive is actually a positive</li>\n",
    "    <li>recall will tell us how good a model is at finding a positive (from amongst all actual positives)</li>\n",
    "    <li>focus on recall when the <b>cost of a false negative</b> (i.e., a positive is identified as a negative) is high</li>\n",
    "    <ul>\n",
    "        <li>Example: Fradulent bank transactions. A bank does not want to misclassify a fradulent transaction as non-fradulent because it may end up costing them money. Here, the focus should be on recall</li>\n",
    "    </ul>\n",
    "    <li>focus on precision when the <b>cost of a false positive is high</b></li>\n",
    "    <ul>\n",
    "        <li>Example: Recommendation systems. It is better not to recommend a movie than to recommend a movie that the user won't like. If you make many bad recommendations (false positives), the user loses interest and you'll end up losing the user</li>\n",
    "    </ul>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<h1>Cross-validation</h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>cross validation is a technique used to measure how well a model will perform out of sample by looking only at in-sample data</li>\n",
    "<li>often used when there is insufficient data</li>\n",
    "<li>or when the data is segmented (e.g., demographic data from different states)</li>\n",
    "<li>procedure:</li>\n",
    "<ol>\n",
    "    <li>split the data into k-groups (aka k-folds)</li>\n",
    "    <li>train the model on k-1 folds</li>\n",
    "    <li>calculate an appropriate metric on the k-th fold</li>\n",
    "    <li>repeat this process on all combinations of (k-1,1) fold sets</li>\n",
    "    <li>report the average (and variance) of those averages as the performance measure</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/lib/python3.9/site-packages/sklearn/datasets/_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784')\n",
    "mnist.keys()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "X,y = mnist['data'],mnist['target']\n",
    "#the pd.assign function adds one or more pandas series as a new column(s) to a dataframe\n",
    "#The function returns a copy\n",
    "df = X.assign(target = y)\n",
    "\n",
    "#Randomly sample 30% of the data without replacement\n",
    "df = df.sample(frac=.3,random_state=42)\n",
    "\n",
    "#Split the data into two dataframes randomly assigning rows to one of two sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size = 0.3,random_state=3456)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['y'] = (train['target'] == '8')\n",
    "test['y'] = (test['target'] == '8')\n",
    "train = train.sample(frac=1.0,random_state=42) \n",
    "X_train = train.iloc[:,0:784]\n",
    "y_train = train['y']\n",
    "X_test = test.iloc[:,0:784]\n",
    "y_test = test['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html\">Stratified K-fold</a></li>\n",
    "<li>StratifiedKFold preserves the ratio of positive and negative cases in each target value</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "nfolds = 3\n",
    "skf = StratifiedKFold(n_splits=nfolds,random_state=42,shuffle=True)\n",
    "skf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:blue;font-size:large\">3-fold cross validation </span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Divide the data into three sets: set1,set2,set3</li>\n",
    "<li>train on set1+set2 and test on set3 get score1</li>\n",
    "<li>train on set1+set3 and test on set2 get score2</li>\n",
    "<li>train on set2+set3 and test on set1 get score3</li>\n",
    "<li>Note that each of score1, score2 and score 3 are calculated on data NOT used for training!</li>\n",
    "<img src=\"crossval.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "<span style=\"color:blue;font-size:large\">Cross validation on the handwritten digits model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number the index from 0..n \n",
    "#sklearn cross validation requires sequential numbering!\n",
    "X_train.index=range(len(X_train))\n",
    "y_train.index=range(len(y_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li><span style=\"color:green\">skf.split</span> splits the data into k sets of (k-1) and 1 and returns the indices of each paired data set</li>\n",
    "<li><span style=\"color:green\">X_train_folds, X_test_folds = X.loc[train_index], X.loc[test_index]</span> extracts the training and testing input feature sets</li>\n",
    "<li><span style=\"color:green\">clone(clf)</span> makes a copy of the SGDClassifier</li>\n",
    "<li><span style=\"color:green\">clone_clf.fit(X_train_folds,y_train_folds)</span> fits the training data (the k-1 folds)</li>\n",
    "<li><span style=\"color:green\">clone_clf.predict(X_test_folds)</span> returns the predictions on the testing (the k-th) fold</li>\n",
    "<li><span style=\"color:green\">(predictions == y_test_folds).sum()/len(predictions)</span> returns the accuracy of the model</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "mean_accuracy = 0\n",
    "for train_index, test_index in skf.split(X_train, y_train):\n",
    "    print(\"Train size:\",len(train_index),\"Test size:\",len(test_index))\n",
    "    X_train_fold, X_test_fold = X_train.loc[train_index], X_train.loc[test_index]\n",
    "    y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
    "    clf_cv = SGDClassifier(random_state=42,max_iter=200)\n",
    "    clf_cv.fit(X_train_fold,y_train_fold)\n",
    "    predictions = clf_cv.predict(X_test_fold)\n",
    "    accuracy = (predictions == y_test_fold).sum()/len(predictions)\n",
    "    mean_accuracy += accuracy\n",
    "    print(\"Fold accuracy:\",accuracy)\n",
    "print(\"Mean accuracy:\",mean_accuracy/nfolds)\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>sklearn support of cross validation</h2>\n",
    "<li>sklearn supports cross validation directly through a set of functions</li>\n",
    "<li>The <i>cross_validate</i> function does the cross validation</li>\n",
    "<li>And returns a list of models and a list of scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.model_selection import cross_val_predict,cross_val_score,cross_validate\n",
    "from sklearn.svm import SVC\n",
    "clf = SGDClassifier(random_state=42,max_iter=100,loss=\"log_loss\",alpha=5)\n",
    "clf_c = cross_validate(clf,X_train,y_train,cv=7,return_estimator=True,\n",
    "                      return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Best model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score,recall_score,accuracy_score\n",
    "b = np.argmax(clf_c['test_score'])\n",
    "best_m = clf_c['estimator'][b]\n",
    "predictions = best_m.predict(X_test)\n",
    "print(\"precision: \", precision_score(y_test, predictions)) #originally 74%\n",
    "print(\"recall: \",recall_score(y_test, predictions)) #originally 66%\n",
    "print(\"accuracy: \", accuracy_score(y_test, predictions)) #originally 94.5%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>The scoring parameter</h4>\n",
    "<li>The scoring parameter tells sklearn what to evaluate the performance on</li>\n",
    "<li>See <a href=\"https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\">https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter</a> for scoring parameter options</li>\n",
    "<li>Example: precision</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.model_selection import cross_val_predict,cross_val_score,cross_validate\n",
    "from sklearn.svm import SVC\n",
    "clf = SGDClassifier(random_state=42,max_iter=100,loss=\"log_loss\",alpha=5)\n",
    "clf_c_p = cross_validate(clf,X_train,y_train,cv=7,return_estimator=True,\n",
    "                      return_train_score=True,scoring=\"f1\")\n",
    "b = np.argmax(clf_c_p['test_score'])\n",
    "best_m = clf_c_p['estimator'][b]\n",
    "predictions = best_m.predict(X_test)\n",
    "print(\"precision: \", precision_score(y_test, predictions)) #originally 74%\n",
    "print(\"recall: \",recall_score(y_test, predictions)) #originally 66%\n",
    "print(\"accuracy: \", accuracy_score(y_test, predictions)) #originally 94.5%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_c_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Why cross validation?</h2>\n",
    "<li>Reduces the probability of overfitting</li>\n",
    "<ul>\n",
    "    <li>Folds are being evaluated on the test score</li>\n",
    "    <li>The variance across folds can be used as a measure of model variance</li>\n",
    "</ul>\n",
    "<li>Cross validation can be used for <b>hyperparameter tuning</b></li>\n",
    "<li>Makes use of all the data. If available data is limited, cross validation can be done on the entire dataset</li>\n",
    "<li>HOWEVER!</li>\n",
    "<ul>\n",
    "    <li>the efficacy of cross validation depends on the number of folds. Too many, and the models may be biased. Too few, and the variance may be high. There is no science in figuring out the number of folds!</li>\n",
    "    <li>cross validation is also more compute intensive since a number of models are being fitted. This can be particularly expensive in hyperparameter tuning</li>\n",
    "</ul>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "81d5b4a19a276010183013345b38f7d9b6c479ab07551a9ca40dd13abdbac5b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
