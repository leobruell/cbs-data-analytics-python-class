{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN3aITynUxMkeZbnpK3WVj1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<h1>Tensorflow</h1>\n","<li>end to end opensource tool for deep learning</li>\n","<li>A <span style=\"color:blue\">tensor</span> is an n-dimensional mathematical object</li>\n","<li>n=0 => scalar</li>\n","<li>n=1 => vector</li>\n","<li>n=2 => matrix</li>\n","<li>tensorflow was built to provide support for numerical computation in high dimensional mathematical objects</li>"],"metadata":{"id":"iyr7boo1yy96"}},{"cell_type":"code","source":["import tensorflow as tf\n","tf.__version__"],"metadata":{"id":"X6fA272VzB1Q","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1679525588418,"user_tz":240,"elapsed":4860,"user":{"displayName":"Hardeep V. Johar","userId":"02151445444133694652"}},"outputId":"09638b65-e7cb-4acf-9544-d3d4dd157bb0"},"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.11.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":[],"metadata":{"id":"kaUvcbkg1c2i","executionInfo":{"status":"ok","timestamp":1679525588418,"user_tz":240,"elapsed":3,"user":{"displayName":"Hardeep V. Johar","userId":"02151445444133694652"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["<h2>Keras</h2>\n","<li>Keras is an open source \"human friendly\" tensorflow wrapper</li>\n","<li>tensorflow provides the math, keras provides an ML interface to tensorflow</li>\n","<li>We'll implement our \"non-linear\" model example in keras/tf</li>"],"metadata":{"id":"7K4lib_l1e42"}},{"cell_type":"code","source":["import numpy as np\n","import keras\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","training_data = np.array([[0,0,1],\n","            [0,1,1],\n","            [1,0,1],\n","            [1,1,1],\n","             [1,1,0],\n","             [0,1,0],\n","             [1,0,0],\n","             [1,0,0]],\"float32\")\n","                \n","y = np.array([[0],[1],[1],[1],[1],[0],[0],[0]],\"float32\")"],"metadata":{"id":"FY1Awf6yy49J","executionInfo":{"status":"ok","timestamp":1679525588418,"user_tz":240,"elapsed":2,"user":{"displayName":"Hardeep V. Johar","userId":"02151445444133694652"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["<h3>Our network</h3>\n","<li>A <b>sequential</b> network (inputs will flow sequentially toward outputs)</li>\n","<li>3 nodes in the input layer (<b>input_dim = 3</b>)</li>\n","<li>A <b>dense</b> network is a fully connected network</li>\n","<li>We'll add a hidden layer of 16 nodes (connected to the 3 input nodes)</li>\n","<li>And an output layer of 1 node</li>"],"metadata":{"id":"6sGQvNsS3575"}},{"cell_type":"code","source":["model = Sequential(name=\"My_Example\")\n","model.add(Dense(16, input_dim=3, activation='relu',name=\"layer_1\")) \n","model.add(Dense(1, activation='sigmoid',name=\"output_layer\"))"],"metadata":{"id":"uIs8TUOT1Wm7","executionInfo":{"status":"ok","timestamp":1679525588911,"user_tz":240,"elapsed":495,"user":{"displayName":"Hardeep V. Johar","userId":"02151445444133694652"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"dHXEStd_2abW"}},{"cell_type":"markdown","source":["<h2>ReLu: Rectified Linear Unit</h2>\n","<li>The sigmoid function, while easy to use, has a drawback</li>\n","<ul>\n","<li>large values snap to 1.0 and -1.0 quickly</li>\n","<li>the function is sensitive around the midpoint (0.5) but not much elsewhere</li>\n","<li>this makes it harder for the algorithm to adapt, and this is especially a problem with large datasets and many layered (deep) networks</li>\n","<li><b>vanishing gradient problem</b>: as the error is backpropagated through many layers, it decreases and the derivative becomes smaller and smaller so the weights barely change. (information is not well utilized)</li>\n","</ul>\n","\n","<li>Relu is a popular activation function</li>\n","\n","<li>The function:\n","<p>\n","$ f_{x} = \\left\\{\\begin{array}{ll}\n","0 & if \\ x\\leq 0 \\\\\n","x & if \\ x \\gt 0\n","\\end{array}\\right.$\n","\n","The function can be rewritten as:\n","\n","$ f_{x} = max(0,x) $\n","\n","linear above 0 and non-linear below 0 (negative values become 0). Linear functions are more generalizable and don't suffer from the vanishing gradient problem\n","\n","\n"],"metadata":{"id":"XDqJ-tuAdFay"}},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZOzVKlmi_8eR","executionInfo":{"status":"ok","timestamp":1679525589055,"user_tz":240,"elapsed":145,"user":{"displayName":"Hardeep V. Johar","userId":"02151445444133694652"}},"outputId":"0e0728d4-557f-4283-85ca-744cced6ba25"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"My_Example\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," layer_1 (Dense)             (None, 16)                64        \n","                                                                 \n"," output_layer (Dense)        (None, 1)                 17        \n","                                                                 \n","=================================================================\n","Total params: 81\n","Trainable params: 81\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["<li><b>Optimizer</b> refers to the algorithm that tweaks weights during backpropogation</li>\n","<li>Typically, stochastic gradient descent is used</li>\n","<li><b>adam</b> extends stochastic gradient descent </li>\n","<ul>\n","<li>faster convergence</li>\n","<li>adaptive learning rates</li>\n","<li>See: <a href=\"https://www.geeksforgeeks.org/intuition-of-adam-optimizer/\">https://www.geeksforgeeks.org/intuition-of-adam-optimizer/</a></li>\n","</ul>\n","<li><b>binary_accuracy</b> is a keras metric that converts predictions (floats between 0 and 1) into 0 or 1 binary values using a threshold of 0.5</li>"],"metadata":{"id":"kjDrsLDXzltO"}},{"cell_type":"code","source":["model.compile(loss='mean_squared_error',\n","              optimizer='adam',\n","              metrics=['binary_accuracy'])"],"metadata":{"id":"TFe42MKX24pr","executionInfo":{"status":"ok","timestamp":1679525589055,"user_tz":240,"elapsed":2,"user":{"displayName":"Hardeep V. Johar","userId":"02151445444133694652"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["model.fit(training_data, y, epochs=200,verbose=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AumwjWlb3fVS","executionInfo":{"status":"ok","timestamp":1679525593064,"user_tz":240,"elapsed":4010,"user":{"displayName":"Hardeep V. Johar","userId":"02151445444133694652"}},"outputId":"d250cb46-c1f4-4e97-b6fe-ff9b8535b582"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f7228d0b970>"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["model.predict(training_data).round() #round returns 0 or 1 rather than the predicted float value\n","#y = np.array([[0],[1],[1],[1],[1],[0],[0],[0]],\"float32\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xQegDzMu3i6a","executionInfo":{"status":"ok","timestamp":1679525593611,"user_tz":240,"elapsed":549,"user":{"displayName":"Hardeep V. Johar","userId":"02151445444133694652"}},"outputId":"dc1da0b7-7e40-4abb-de9d-6f2d3d66a2d4"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 253ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[1.],\n","       [1.],\n","       [1.],\n","       [1.],\n","       [1.],\n","       [0.],\n","       [0.],\n","       [0.]], dtype=float32)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["test_data = np.array([[1, 1, 1],\n","       [0, 1, 1],\n","       [1, 0, 0],\n","       [0, 0, 1]],\"float32\")\n","model.predict(test_data).round()"],"metadata":{"id":"i5ucxGWZ7_XO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679525593847,"user_tz":240,"elapsed":239,"user":{"displayName":"Hardeep V. Johar","userId":"02151445444133694652"}},"outputId":"25a7720e-7f81-4ce7-f737-bb10c897325c"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 107ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[1.],\n","       [1.],\n","       [0.],\n","       [1.]], dtype=float32)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":[],"metadata":{"id":"OgirpCiK-loJ","executionInfo":{"status":"ok","timestamp":1679525593847,"user_tz":240,"elapsed":4,"user":{"displayName":"Hardeep V. Johar","userId":"02151445444133694652"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["<h1>Classifying handwritten digits</h1>\n","<li>Let's use a neural net to build a handwritten digits predictor</li>"],"metadata":{"id":"R5cnm1gjIuKs"}},{"cell_type":"code","source":["from sklearn.datasets import fetch_openml\n","mnist = fetch_openml('mnist_784')\n","mnist.keys()"],"metadata":{"id":"bbkDhdFhgQ8O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679525642919,"user_tz":240,"elapsed":49075,"user":{"displayName":"Hardeep V. Johar","userId":"02151445444133694652"}},"outputId":"b58eca83-ece5-4437-de95-039a51cec321"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n","  warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["<li>Let's take a look at the data by drawing the digits</li>"],"metadata":{"id":"g2d574j8nVqb"}},{"cell_type":"code","source":["digit_number = 37833\n","for line in mnist.data.to_numpy()[digit_number].reshape(28,28):\n","    for num in line:\n","        if num > 0:\n","            print('*', end = ' ')\n","        else:\n","            print(' ', end = ' ')\n","    print('')\n","print(\"Actual value: \",mnist.target.to_numpy()[digit_number])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zUu8TSaqMF98","executionInfo":{"status":"ok","timestamp":1679525642919,"user_tz":240,"elapsed":4,"user":{"displayName":"Hardeep V. Johar","userId":"02151445444133694652"}},"outputId":"0dc7e2a0-d822-4e2d-8cb6-5c72876d75c5"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                        \n","                                                        \n","                                                        \n","                                                        \n","                                                        \n","                                                        \n","                        * * * * *                       \n","                      * * * * * *                       \n","                    * * * * * * * * * * * * *           \n","                    * * * * * * * * * * * * *           \n","                  * * * * * * * * * * * * * *           \n","                * * * * * * * *   * * * * * *           \n","              * * * * * * *       * * * * * *           \n","              * * * * * *       * * * * * *             \n","              * * * * *       * * * * * *               \n","              * * *           * * * * *                 \n","                            * * * * *                   \n","                          * * * * * *                   \n","                        * * * * * *                     \n","                      * * * * * *                       \n","                    * * * * * *                         \n","                  * * * * * *                           \n","              * * * * * * * *                           \n","              * * * * * *                               \n","              * * * *                                   \n","              * * * *                                   \n","                                                        \n","                                                        \n","Actual value:  7\n"]}]},{"cell_type":"markdown","source":["<h3>Training and testing data</h3>\n","<li>The data is in a tuple ((training data, training labels), (testing data, testing labels)) </li>\n","<li>extract training (60,000) and testing (10,000) data</li>\n","<li>normalize the independent variables</li>\n","<li>one hot encode the target values using <b>to_categorical</b> (keras one hot encoding function)</li>"],"metadata":{"id":"3Cpg2v6ip84p"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from tensorflow.keras.utils import to_categorical\n","tf.random.set_seed(7)\n","from sklearn.model_selection import train_test_split\n","\n","mnist = keras.datasets.mnist\n","(train_iv, train_dv), (test_iv,\n","                               test_dv) = mnist.load_data()\n","\n","# Standardize the data.\n","mean = np.mean(train_iv)\n","stddev = np.std(train_iv)\n","train_iv = (train_iv - mean) / stddev\n","test_iv = (test_iv - mean) / stddev\n","\n","# One-hot encode labels.\n","train_dv = to_categorical(train_dv, num_classes=10)\n","test_dv = to_categorical(test_dv, num_classes=10)"],"metadata":{"id":"rVK3M1WSMssJ","executionInfo":{"status":"ok","timestamp":1678772274225,"user_tz":-330,"elapsed":1486,"user":{"displayName":"Hardeep V. Johar","userId":"02151445444133694652"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"723f8161-a4dc-4060-99a8-2b861d6695af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["test_dv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nDEE5FvltfWl","executionInfo":{"status":"ok","timestamp":1678772284833,"user_tz":-330,"elapsed":421,"user":{"displayName":"Hardeep V. Johar","userId":"02151445444133694652"}},"outputId":"ebfe5462-9df9-4296-a538-d73631ef785a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., ..., 1., 0., 0.],\n","       [0., 0., 1., ..., 0., 0., 0.],\n","       [0., 1., 0., ..., 0., 0., 0.],\n","       ...,\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.],\n","       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":[],"metadata":{"id":"88a9NIPgtCA-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<h2>Creating the neural network</h2>\n","<li>We'll create a Sequential network as in our earlier example</li>\n","<li>"],"metadata":{"id":"6xW1Z1JdvtEv"}},{"cell_type":"code","source":["# Object used to initialize weights.\n","initializer = keras.initializers.RandomUniform(\n","    minval=-0.1, maxval=0.1)\n","\n","# Create a Sequential model.\n","\n","model = keras.Sequential([\n","    keras.layers.Flatten(input_shape=(28, 28)), #Converts each 28x28 matrix into a 784 vector\n","    keras.layers.Dense(25, activation='tanh', #the tanh activation function (values from -1 to 1 unlike sigmoid 0 to 1)\n","                       kernel_initializer=initializer,\n","                       bias_initializer='zeros'), #a bias input vector for regularization\n","    keras.layers.Dense(10, activation='relu', #output layer - 10 values, relu activation (fires/doesn't fire)\n","                       kernel_initializer=initializer,\n","                       bias_initializer='zeros')])"],"metadata":{"id":"VX813iCnv5ZT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<h3>Training Parameters</h3>\n","<li><b>EPOCH</b>: Number of training passes</li>\n","<li><b>Batch Size</b>: Number of cases used to update the network (batch size = 1 means that each case is passed through the network and weights are updated. 60000 in each epoch!</li>\n","<li><b>Initializer</b>: An object that picks values from a uniform distribution between -0.1 and 0.1</li>\n"],"metadata":{"id":"bPYDGmr6ZnOx"}},{"cell_type":"code","source":["\n","\n","EPOCHS = 5\n","BATCH_SIZE = 4000"],"metadata":{"id":"ixsg3Gv-zvzl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# SGD optimizer with learning rate of 0.01\n","# MSE loss function\n","\n","opt = tf.keras.optimizers.SGD(learning_rate=0.01)\n","\n","model.compile(loss='mean_squared_error', optimizer = opt,\n","              metrics =['accuracy'])\n","\n","# Train the model for 5 epochs (result for 20 epochs is below)\n","# Shuffle (randomize) order.\n","# Update weights after each example (batch_size=1).\n","history = model.fit(train_iv, train_dv,\n","                    validation_data=(test_iv, test_dv),\n","                    epochs=EPOCHS, batch_size=BATCH_SIZE,\n","                    verbose=2, shuffle=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EEZjNqOSv-mD","executionInfo":{"status":"ok","timestamp":1678772346250,"user_tz":-330,"elapsed":3401,"user":{"displayName":"Hardeep V. Johar","userId":"02151445444133694652"}},"outputId":"f4304164-44e1-4a7d-fedb-fcf62e93422d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","15/15 - 1s - loss: 0.1051 - accuracy: 0.1207 - val_loss: 0.1039 - val_accuracy: 0.1272 - 963ms/epoch - 64ms/step\n","Epoch 2/5\n","15/15 - 0s - loss: 0.1031 - accuracy: 0.1311 - val_loss: 0.1021 - val_accuracy: 0.1357 - 358ms/epoch - 24ms/step\n","Epoch 3/5\n","15/15 - 0s - loss: 0.1015 - accuracy: 0.1393 - val_loss: 0.1006 - val_accuracy: 0.1447 - 342ms/epoch - 23ms/step\n","Epoch 4/5\n","15/15 - 0s - loss: 0.1000 - accuracy: 0.1474 - val_loss: 0.0992 - val_accuracy: 0.1516 - 336ms/epoch - 22ms/step\n","Epoch 5/5\n","15/15 - 0s - loss: 0.0988 - accuracy: 0.1557 - val_loss: 0.0980 - val_accuracy: 0.1581 - 353ms/epoch - 24ms/step\n"]}]},{"cell_type":"markdown","source":["<li><b>loss</b>: mean square error on the training set</li>\n","<li><b>accuracy</b>: accuracy on the training set</li>\n","<li><b>val_loss</b>: mean square error on the test set</li>\n","<li><b>val_accuracy</b>: accuracy on the test set</li>\n","<li>Progression of stats across 20 epochs:</li>\n","<pre>\n","Epoch 1/20\n","60000/60000 - 72s - loss: 0.0549 - accuracy: 0.6740 - val_loss: 0.0284 - val_accuracy: 0.8826 - 72s/epoch - 1ms/step\n","Epoch 2/20\n","60000/60000 - 73s - loss: 0.0226 - accuracy: 0.8900 - val_loss: 0.0182 - val_accuracy: 0.9063 - 73s/epoch - 1ms/step\n","Epoch 3/20\n","60000/60000 - 72s - loss: 0.0173 - accuracy: 0.9062 - val_loss: 0.0158 - val_accuracy: 0.9153 - 72s/epoch - 1ms/step\n","Epoch 4/20\n","60000/60000 - 73s - loss: 0.0153 - accuracy: 0.9149 - val_loss: 0.0145 - val_accuracy: 0.9192 - 73s/epoch - 1ms/step\n","Epoch 5/20\n","60000/60000 - 73s - loss: 0.0142 - accuracy: 0.9196 - val_loss: 0.0136 - val_accuracy: 0.9235 - 73s/epoch - 1ms/step\n","Epoch 6/20\n","60000/60000 - 72s - loss: 0.0134 - accuracy: 0.9235 - val_loss: 0.0131 - val_accuracy: 0.9264 - 72s/epoch - 1ms/step\n","Epoch 7/20\n","60000/60000 - 73s - loss: 0.0128 - accuracy: 0.9269 - val_loss: 0.0129 - val_accuracy: 0.9241 - 73s/epoch - 1ms/step\n","Epoch 8/20\n","60000/60000 - 72s - loss: 0.0124 - accuracy: 0.9292 - val_loss: 0.0125 - val_accuracy: 0.9283 - 72s/epoch - 1ms/step\n","Epoch 9/20\n","60000/60000 - 73s - loss: 0.0119 - accuracy: 0.9312 - val_loss: 0.0122 - val_accuracy: 0.9300 - 73s/epoch - 1ms/step\n","Epoch 10/20\n","60000/60000 - 74s - loss: 0.0116 - accuracy: 0.9333 - val_loss: 0.0122 - val_accuracy: 0.9298 - 74s/epoch - 1ms/step\n","Epoch 11/20\n","60000/60000 - 72s - loss: 0.0112 - accuracy: 0.9354 - val_loss: 0.0118 - val_accuracy: 0.9314 - 72s/epoch - 1ms/step\n","Epoch 12/20\n","60000/60000 - 73s - loss: 0.0110 - accuracy: 0.9378 - val_loss: 0.0118 - val_accuracy: 0.9297 - 73s/epoch - 1ms/step\n","Epoch 13/20\n","60000/60000 - 73s - loss: 0.0107 - accuracy: 0.9394 - val_loss: 0.0114 - val_accuracy: 0.9339 - 73s/epoch - 1ms/step\n","Epoch 14/20\n","60000/60000 - 73s - loss: 0.0104 - accuracy: 0.9407 - val_loss: 0.0114 - val_accuracy: 0.9324 - 73s/epoch - 1ms/step\n","Epoch 15/20\n","60000/60000 - 73s - loss: 0.0102 - accuracy: 0.9419 - val_loss: 0.0111 - val_accuracy: 0.9345 - 73s/epoch - 1ms/step\n","Epoch 16/20\n","60000/60000 - 83s - loss: 0.0100 - accuracy: 0.9430 - val_loss: 0.0109 - val_accuracy: 0.9357 - 83s/epoch - 1ms/step\n","Epoch 17/20\n","60000/60000 - 73s - loss: 0.0098 - accuracy: 0.9441 - val_loss: 0.0110 - val_accuracy: 0.9346 - 73s/epoch - 1ms/step\n","Epoch 18/20\n","60000/60000 - 73s - loss: 0.0097 - accuracy: 0.9446 - val_loss: 0.0110 - val_accuracy: 0.9342 - 73s/epoch - 1ms/step\n","Epoch 19/20\n","60000/60000 - 72s - loss: 0.0095 - accuracy: 0.9457 - val_loss: 0.0108 - val_accuracy: 0.9362 - 72s/epoch - 1ms/step\n","Epoch 20/20\n","60000/60000 - 73s - loss: 0.0094 - accuracy: 0.9466 - val_loss: 0.0107 - val_accuracy: 0.9359 - 73s/epoch - 1ms/step\n","</pre>"],"metadata":{"id":"3uXpPLRf9wZA"}},{"cell_type":"code","source":[],"metadata":{"id":"D9BP7YT_jnkr"},"execution_count":null,"outputs":[]}]}